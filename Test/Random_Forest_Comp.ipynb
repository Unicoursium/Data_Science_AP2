{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b79150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Income', 'Recency', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp4', 'AcceptedCmp5', 'DaysSinceSignup', 'Education_PhD', 'TotalSpent']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     58\u001b[39m X_reduced = X_full[important_features]\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(important_features)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m coef_reduced = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFeature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_reduced\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mImportance\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf_init\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature_importances_\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m.sort_values(by=\u001b[33m\"\u001b[39m\u001b[33mImportance\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFeature Importance Table\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(coef_reduced)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Unico\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Unico\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Unico\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Unico\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    675\u001b[39m lengths = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll arrays must be of the same length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    682\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# 全流程：预处理 ➜ 特征精简 ➜ 两套 RandomForest ➜ 结果对比\n",
    "# ===============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------------- 读取数据（正确分隔符 ;） ----------------\n",
    "df = pd.read_csv('marketing_campaign_CLEANED.csv', sep=',')\n",
    "\n",
    "# ---------- ① 解析 Dt_Customer 并生成天数字段 ----------\n",
    "df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'], format='%d-%m-%Y')\n",
    "\n",
    "# 以数据集中最晚日期为“今天”，也可改为 datetime(2025,1,1)\n",
    "ref_date = df['Dt_Customer'].max()\n",
    "df['DaysSinceSignup'] = (ref_date - df['Dt_Customer']).dt.days\n",
    "\n",
    "# ---------- ② 常规预处理 ----------\n",
    "df['Age'] = 2025 - df['Year_Birth']\n",
    "df = df[df['Age'] <= 100]\n",
    "df = df.dropna(subset=['Income'])\n",
    "\n",
    "# One-Hot 编码\n",
    "df = pd.get_dummies(df, columns=['Education', 'Marital_Status'], drop_first=True)\n",
    "\n",
    "# 构造 TotalSpent（不含 MntWines）\n",
    "df['TotalSpent'] = df[['MntFruits','MntMeatProducts','MntFishProducts',\n",
    "                       'MntSweetProducts','MntGoldProds']].sum(axis=1)\n",
    "\n",
    "# 活跃过滤\n",
    "Setting_Amount = 50\n",
    "df['TotalSpendingAll'] = df[['MntWines','MntFruits','MntMeatProducts',\n",
    "                             'MntFishProducts','MntSweetProducts','MntGoldProds']].sum(axis=1)\n",
    "df_active = df[df['TotalSpendingAll'] >= Setting_Amount].copy()\n",
    "\n",
    "# ---------- ③ 删除原始日期列，保留 DaysSinceSignup ----------\n",
    "df_active = df_active.drop(columns=['Dt_Customer'])\n",
    "\n",
    "# ---------- ④ 目标 & 特征 ----------\n",
    "y = df_active['MntWines'].astype(float)\n",
    "X_full = df_active.drop(['MntWines', 'TotalSpendingAll'], axis=1)\n",
    "\n",
    "\n",
    "# ----------------------- 3. 先做一次 RF 获取重要性 ------------------\n",
    "rf_init = RandomForestRegressor(\n",
    "    n_estimators=400, random_state=42, n_jobs=-1)\n",
    "rf_init.fit(X_full, y)\n",
    "\n",
    "# 依据重要性阈值 0.01 精简特征\n",
    "imp_series = pd.Series(rf_init.feature_importances_, index=X_full.columns)\n",
    "important_features = imp_series[imp_series > 0.01].index.tolist()\n",
    "X_reduced = X_full[important_features]\n",
    "print(important_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"❯❯ 重要性阈值 0.01 后，特征数：{len(important_features)} / {X_full.shape[1]}\")\n",
    "\n",
    "# ----------------------- 4. 统一划分训练/测试 -----------------------\n",
    "# 使用相同 random_state 保证索引一致\n",
    "X_train_full, X_test_full, y_train, y_test = train_test_split(\n",
    "    X_full, y, test_size=0.20, random_state=42)\n",
    "X_train_red  = X_train_full[important_features]\n",
    "X_test_red   = X_test_full[important_features]\n",
    "\n",
    "# ----------------------- 5. 训练两套 RandomForest ------------------\n",
    "# 你可将 param_grid 调整为更大范围做 GridSearchCV，这里直接给常用参数\n",
    "rf_params = {'n_estimators': 500, 'max_depth': None,\n",
    "             'min_samples_split': 2, 'min_samples_leaf': 1,\n",
    "             'random_state': 42, 'n_jobs': -1}\n",
    "\n",
    "rf_full  = RandomForestRegressor(**rf_params).fit(X_train_full, y_train)\n",
    "rf_red   = RandomForestRegressor(**rf_params).fit(X_train_red,  y_train)\n",
    "\n",
    "# ----------------------- 6. 预测 & 指标对比 ------------------------\n",
    "pred_full = rf_full.predict(X_test_full)\n",
    "pred_red  = rf_red.predict(X_test_red)\n",
    "\n",
    "r2_full,  mse_full  = r2_score(y_test, pred_full), mean_squared_error(y_test, pred_full)\n",
    "r2_red,   mse_red   = r2_score(y_test, pred_red),  mean_squared_error(y_test, pred_red)\n",
    "\n",
    "print(\"\\n================= RandomForest 对比 =================\")\n",
    "print(f\"{'模型':<15}{'特征数':<8}{'R²':>8}{'MSE':>12}\")\n",
    "print(f\"{'Full RF':<15}{X_full.shape[1]:<8}{r2_full:8.3f}{mse_full:12.2f}\")\n",
    "print(f\"{'Reduced RF':<15}{len(important_features):<8}{r2_red:8.3f}{mse_red:12.2f}\")\n",
    "\n",
    "# ----------------------- 7. 可视化散点图 --------------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,5), sharey=True, sharex=True)\n",
    "\n",
    "axes[0].scatter(y_test, pred_full, alpha=0.5, color='steelblue')\n",
    "axes[0].plot([y_test.min(), y_test.max()],\n",
    "             [y_test.min(), y_test.max()], 'r--')\n",
    "axes[0].set_title(f'Full RF (R²={r2_full:.3f})')\n",
    "axes[0].set_xlabel(\"Actual\")\n",
    "axes[0].set_ylabel(\"Predicted\")\n",
    "\n",
    "axes[1].scatter(y_test, pred_red, alpha=0.5, color='seagreen')\n",
    "axes[1].plot([y_test.min(), y_test.max()],\n",
    "             [y_test.min(), y_test.max()], 'r--')\n",
    "axes[1].set_title(f'Reduced RF (R²={r2_red:.3f})')\n",
    "axes[1].set_xlabel(\"Actual\")\n",
    "\n",
    "plt.suptitle(\"Predicted vs Actual Red Wine Spending\\nFull vs Reduced Feature Sets\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------- 8. 保存精简模型（可选） ---------------------\n",
    "joblib.dump(rf_red, 'redwine_rf_reduced.pkl')\n",
    "print(\"✓ 精简 RandomForest 已保存为 redwine_rf_reduced.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
